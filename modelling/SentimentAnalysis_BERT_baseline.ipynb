{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "trying-threshold",
   "metadata": {},
   "source": [
    "# Simple Transformers Model\n",
    "\n",
    "- Documentation: https://simpletransformers.ai/docs/binary-classification/\n",
    "- Model Types: https://simpletransformers.ai/docs/classification-specifics/#supported-model-types\n",
    "- Github: https://github.com/ThilinaRajapakse/simpletransformers\n",
    "- Tutorials:\n",
    "    - https://towardsdatascience.com/simple-transformers-introducing-the-easiest-bert-roberta-xlnet-and-xlm-library-58bf8c59b2a3\n",
    "    - https://medium.com/towards-artificial-intelligence/text-classification-with-simple-transformers-a29d13358135\n",
    "    - https://towardsdatascience.com/battle-of-the-transformers-electra-bert-roberta-or-xlnet-40607e97aba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# model training\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.special import softmax\n",
    "\n",
    "# for display\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ancient-empire",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-governor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path and filenames\n",
    "path = 'data/labelled_data/'\n",
    "train = 'train'\n",
    "val = 'val'\n",
    "test = 'test'\n",
    "suffix = '_newpreproc_emoticon.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data dict\n",
    "data = {}\n",
    "data_names = [train, val, test]\n",
    "# change this accordingly: 'phrase', 'phrase_lemma', 'phrase_stem'\n",
    "text_column = 'phrase'\n",
    "# old_new = 'new_preproc'\n",
    "\n",
    "for name in data_names:\n",
    "    # read data\n",
    "    df = pd.read_csv(path+name+suffix)\n",
    "    df['label'] = df['label'].astype('int32')\n",
    "    # rename columns - requirement of the simpletransformers package\n",
    "    df = df.rename({'label': 'labels'}, axis=1)\n",
    "    df = df.rename({text_column: 'text'}, axis=1)\n",
    "    # add to data dict\n",
    "    data[f'{name}_{text_column}'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in data.items():\n",
    "    print(df_name)\n",
    "    print(df.shape)\n",
    "    print(df.labels.value_counts())\n",
    "    display(df.head(3))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-snowboard",
   "metadata": {},
   "source": [
    "## Baseline: Yelp Polarity Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise model\n",
    "model_baseline_args = ClassificationArgs(num_train_epochs=2, learning_rate = 5e-5)\n",
    "model_baseline = ClassificationModel(model_type = 'bert', \\\n",
    "                                     model_name = 'textattack/bert-base-uncased-yelp-polarity', \\\n",
    "                                     args = model_baseline_args, use_cuda = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-bracelet",
   "metadata": {},
   "source": [
    "###Â Predict on Validation\n",
    "\n",
    "- To find the best threshold to classify phrases into 3 categories: -1, 0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on val set\n",
    "val_pred, val_raw_outputs = model_baseline.predict(data['val_'+text_column].text)\n",
    "\n",
    "# append prediction and output to df\n",
    "val_pred_df = data['val_'+text_column].copy()\n",
    "val_pred_df['raw_pred'] = val_pred\n",
    "for i in range(len(val_pred_df)):\n",
    "    val_pred_df.loc[i, 'raw_output_0'] = val_raw_outputs[i][0]\n",
    "    val_pred_df.loc[i, 'raw_output_1'] = val_raw_outputs[i][1]\n",
    "    \n",
    "# get probabilities (note 0 means negative and 1 means positive)\n",
    "val_prob = softmax(val_raw_outputs, axis=1)\n",
    "\n",
    "val_prob_positive = [x[1] for x in val_prob]\n",
    "val_pred_df['prob_pos'] = val_prob_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-muscle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that assigns class labels based on prob (positive sentiment)\n",
    "def label_from_prob(x, lower, upper):    \n",
    "    if x < lower: # negative sentiment\n",
    "        return -1\n",
    "    elif x < upper: # neutral sentiment\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-celebration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search for best threshold\n",
    "lower_lst = [round(i*0.05, 2) for i in range(1, 9)]\n",
    "upper_lst = [round(1 - i, 2) for i in lower_lst]\n",
    "\n",
    "# dataframe to store results\n",
    "val_threshold_results = pd.DataFrame(columns = ['lower_thresh', 'upper_thresh', 'accuracy', \\\n",
    "                                                'weighted_ave_f1', 'f1_neg', 'f1_zero', 'f1_pos'])\n",
    "\n",
    "for i in range(len(lower_lst)):\n",
    "    df = val_pred_df.copy()\n",
    "    # assign labels based on threshold definition\n",
    "    lower = lower_lst[i]\n",
    "    upper = upper_lst[i]\n",
    "    df['pred'] = df.apply(lambda x: label_from_prob(x.prob_pos, lower, upper), axis=1)\n",
    "    \n",
    "    # classification report\n",
    "    report = classification_report(df.labels, df.pred, output_dict=True)\n",
    "    # retrieve metrics\n",
    "    accuracy = report['accuracy']\n",
    "    weighted_ave_f1 = report['weighted avg']['f1-score']\n",
    "    f1_neg = report['-1']['f1-score']\n",
    "    f1_zero = report['0']['f1-score']\n",
    "    f1_pos = report['1']['f1-score']\n",
    "    \n",
    "    row = {'lower_thresh': lower, 'upper_thresh': upper, 'accuracy': accuracy, \\\n",
    "           'weighted_ave_f1': weighted_ave_f1, 'f1_neg': f1_neg, 'f1_zero': f1_zero, 'f1_pos': f1_pos}\n",
    "    \n",
    "    val_threshold_results = val_threshold_results.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-involvement",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_threshold_results.to_csv(f'model_results/bert/baseline/val_threshold_{text_column}.csv')\n",
    "val_threshold_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-enemy",
   "metadata": {},
   "source": [
    "### Apply Best Threshold on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_row = val_threshold_results.loc[val_threshold_results['weighted_ave_f1'] == max(val_threshold_results['weighted_ave_f1'])]\n",
    "best_lower = best_row['lower_thresh'][0]\n",
    "best_upper = best_row['upper_thresh'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "test_pred, test_raw_outputs = model_baseline.predict(data['test_'+text_column].text)\n",
    "\n",
    "# append prediction and output to df\n",
    "test_pred_df = data['test_'+text_column].copy()\n",
    "test_pred_df['raw_pred'] = test_pred\n",
    "for i in range(len(test_pred_df)):\n",
    "    test_pred_df.loc[i, 'raw_output_0'] = test_raw_outputs[i][0]\n",
    "    test_pred_df.loc[i, 'raw_output_1'] = test_raw_outputs[i][1]\n",
    "    \n",
    "# get probabilities (note 0 means negative and 1 means positive)\n",
    "test_prob = softmax(test_raw_outputs, axis=1)\n",
    "\n",
    "test_prob_positive = [x[1] for x in test_prob]\n",
    "test_pred_df['prob_pos'] = test_prob_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df['pred'] = test_pred_df.apply(lambda x: label_from_prob(x['prob_pos'], best_lower, best_upper), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-pakistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = classification_report(test_pred_df.labels, test_pred_df.pred, output_dict=True)\n",
    "# save to txt\n",
    "f = open(f'model_results/bert/baseline/test_{text_column}.txt', \"w\")\n",
    "f.write( str(test_results) )\n",
    "f.close()\n",
    "\n",
    "print(classification_report(test_pred_df.labels, test_pred_df.pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df.pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-powell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-hindu",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-guess",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
