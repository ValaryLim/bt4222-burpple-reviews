{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as npu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Aggregated Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"new_labels/test_newpreproc_emoticon/train_newpreproc_emoticon.csv\")\n",
    "val = pd.read_csv(\"new_labels/test_newpreproc_emoticon/val_newpreproc_emoticon.csv\")\n",
    "test = pd.read_csv(\"new_labels/test_newpreproc_emoticon/test_newpreproc_emoticon.csv\")\n",
    "trainval = pd.concat([train,val],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2486, 15), (775, 15))"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainval.shape,test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER\n",
    "\n",
    "Developed in 2014, VADER (Valence Aware Dictionary and sEntiment Reasoner) is a pre-trained model that uses rule-based values tuned to sentiments from social media. It evaluates the text of a message and gives you an assessment of not just positive and negative, but the intensity of that emotion as well.\n",
    "\n",
    "It uses a dictionary of terms that it can evaluate. From the GitHub repository this includes examples like:\n",
    "\n",
    "Negations - a modifier that reverses the meaning of a phrase (\"not great\").\n",
    "Contractions - negations, but more complex (\"wasn’t great\").\n",
    "Punctuation - increased intensity (\"It’s great!!!\").\n",
    "Slang - variations of slang words such as \"kinda\", \"sux\", or \"hella\".\n",
    "It's even able to understand acronyms (\"lol\") and emoji (❤).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/xinminaw/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.3182}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(\"fresh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>restaurant_code</th>\n",
       "      <th>review_title</th>\n",
       "      <th>account_name</th>\n",
       "      <th>new_aspect_1</th>\n",
       "      <th>phrase</th>\n",
       "      <th>phrase_lemma</th>\n",
       "      <th>phrase_stem</th>\n",
       "      <th>phrase_emoticon_generic</th>\n",
       "      <th>phrase_emoticon_unique</th>\n",
       "      <th>phrase_stem_emoticon_generic</th>\n",
       "      <th>phrase_lemma_emoticon_generic</th>\n",
       "      <th>phrase_stem_emoticon_unique</th>\n",
       "      <th>phrase_lemma_emoticon_unique</th>\n",
       "      <th>label</th>\n",
       "      <th>polarity_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109-teochew-yong-tau-foo</td>\n",
       "      <td>Ampang YTF!</td>\n",
       "      <td>Pearlyn Chua</td>\n",
       "      <td>ambience</td>\n",
       "      <td>airconditioned price point loving place ca wai...</td>\n",
       "      <td>airconditioned price point loving place ca wai...</td>\n",
       "      <td>aircondit price point love place ca wait visit</td>\n",
       "      <td>airconditioned price point loving place ca wai...</td>\n",
       "      <td>airconditioned price point loving place ca wai...</td>\n",
       "      <td>aircondit price point love place ca wait visit</td>\n",
       "      <td>airconditioned price point loving place ca wai...</td>\n",
       "      <td>aircondit price point love place ca wait visit</td>\n",
       "      <td>airconditioned price point loving place ca wai...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.642, 'pos': 0.358, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>109-teochew-yong-tau-foo</td>\n",
       "      <td>Ampang YTF!</td>\n",
       "      <td>Pearlyn Chua</td>\n",
       "      <td>food</td>\n",
       "      <td>soup dry laksa fried rice fried chicken wings ...</td>\n",
       "      <td>soup dry laksa fried rice fried chicken wing b...</td>\n",
       "      <td>soup dri laksa fri rice fri chicken wing brown...</td>\n",
       "      <td>soup dry laksa fried rice fried chicken wings ...</td>\n",
       "      <td>soup dry laksa fried rice fried chicken wings ...</td>\n",
       "      <td>soup dri laksa fri rice fri chicken wing brown...</td>\n",
       "      <td>soup dry laksa fried rice fried chicken wing b...</td>\n",
       "      <td>soup dri laksa fri rice fri chicken wing brown...</td>\n",
       "      <td>soup dry laksa fried rice fried chicken wing b...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'neg': 0.063, 'neu': 0.663, 'pos': 0.274, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109-teochew-yong-tau-foo</td>\n",
       "      <td>Ampang YTF!</td>\n",
       "      <td>Pearlyn Chua</td>\n",
       "      <td>time</td>\n",
       "      <td>snaking queue intimidated long cos moves fairl...</td>\n",
       "      <td>snaking queue intimidated long co move fairly ...</td>\n",
       "      <td>snake queue intimid long co move fairli fast</td>\n",
       "      <td>snaking queue intimidated long cos moves fairl...</td>\n",
       "      <td>snaking queue intimidated long cos moves fairl...</td>\n",
       "      <td>snake queue intimid long co move fairli fast</td>\n",
       "      <td>snaking queue intimidated long co move fairly ...</td>\n",
       "      <td>snake queue intimid long co move fairli fast</td>\n",
       "      <td>snaking queue intimidated long co move fairly ...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>{'neg': 0.293, 'neu': 0.707, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>109-teochew-yong-tau-foo</td>\n",
       "      <td>Delicious Yong Tau Foo</td>\n",
       "      <td>Simple Foodie</td>\n",
       "      <td>food</td>\n",
       "      <td>yong tau foohidden circular road smack town sh...</td>\n",
       "      <td>yong tau foohidden circular road smack town sh...</td>\n",
       "      <td>yong tau foohidden circular road smack town sh...</td>\n",
       "      <td>yong tau foohidden circular road smack town sh...</td>\n",
       "      <td>yong tau foohidden circular road smack town sh...</td>\n",
       "      <td>yong tau foohidden circular road smack town sh...</td>\n",
       "      <td>yong tau foohidden circular road smack town sh...</td>\n",
       "      <td>yong tau foohidden circular road smack town sh...</td>\n",
       "      <td>yong tau foohidden circular road smack town sh...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>109-teochew-yong-tau-foo</td>\n",
       "      <td>Delicious Yong Tau Foo</td>\n",
       "      <td>Simple Foodie</td>\n",
       "      <td>time</td>\n",
       "      <td>clear queue</td>\n",
       "      <td>clear queue</td>\n",
       "      <td>clear queue</td>\n",
       "      <td>clear queue</td>\n",
       "      <td>clear queue</td>\n",
       "      <td>clear queue</td>\n",
       "      <td>clear queue</td>\n",
       "      <td>clear queue</td>\n",
       "      <td>clear queue</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.278, 'pos': 0.722, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           restaurant_code            review_title  \\\n",
       "0           0  109-teochew-yong-tau-foo             Ampang YTF!   \n",
       "1           1  109-teochew-yong-tau-foo             Ampang YTF!   \n",
       "2           2  109-teochew-yong-tau-foo             Ampang YTF!   \n",
       "3           3  109-teochew-yong-tau-foo  Delicious Yong Tau Foo   \n",
       "4           4  109-teochew-yong-tau-foo  Delicious Yong Tau Foo   \n",
       "\n",
       "    account_name new_aspect_1  \\\n",
       "0   Pearlyn Chua     ambience   \n",
       "1   Pearlyn Chua         food   \n",
       "2   Pearlyn Chua         time   \n",
       "3  Simple Foodie         food   \n",
       "4  Simple Foodie         time   \n",
       "\n",
       "                                              phrase  \\\n",
       "0  airconditioned price point loving place ca wai...   \n",
       "1  soup dry laksa fried rice fried chicken wings ...   \n",
       "2  snaking queue intimidated long cos moves fairl...   \n",
       "3  yong tau foohidden circular road smack town sh...   \n",
       "4                                        clear queue   \n",
       "\n",
       "                                        phrase_lemma  \\\n",
       "0  airconditioned price point loving place ca wai...   \n",
       "1  soup dry laksa fried rice fried chicken wing b...   \n",
       "2  snaking queue intimidated long co move fairly ...   \n",
       "3  yong tau foohidden circular road smack town sh...   \n",
       "4                                        clear queue   \n",
       "\n",
       "                                         phrase_stem  \\\n",
       "0     aircondit price point love place ca wait visit   \n",
       "1  soup dri laksa fri rice fri chicken wing brown...   \n",
       "2       snake queue intimid long co move fairli fast   \n",
       "3  yong tau foohidden circular road smack town sh...   \n",
       "4                                        clear queue   \n",
       "\n",
       "                             phrase_emoticon_generic  \\\n",
       "0  airconditioned price point loving place ca wai...   \n",
       "1  soup dry laksa fried rice fried chicken wings ...   \n",
       "2  snaking queue intimidated long cos moves fairl...   \n",
       "3  yong tau foohidden circular road smack town sh...   \n",
       "4                                        clear queue   \n",
       "\n",
       "                              phrase_emoticon_unique  \\\n",
       "0  airconditioned price point loving place ca wai...   \n",
       "1  soup dry laksa fried rice fried chicken wings ...   \n",
       "2  snaking queue intimidated long cos moves fairl...   \n",
       "3  yong tau foohidden circular road smack town sh...   \n",
       "4                                        clear queue   \n",
       "\n",
       "                        phrase_stem_emoticon_generic  \\\n",
       "0     aircondit price point love place ca wait visit   \n",
       "1  soup dri laksa fri rice fri chicken wing brown...   \n",
       "2       snake queue intimid long co move fairli fast   \n",
       "3  yong tau foohidden circular road smack town sh...   \n",
       "4                                        clear queue   \n",
       "\n",
       "                       phrase_lemma_emoticon_generic  \\\n",
       "0  airconditioned price point loving place ca wai...   \n",
       "1  soup dry laksa fried rice fried chicken wing b...   \n",
       "2  snaking queue intimidated long co move fairly ...   \n",
       "3  yong tau foohidden circular road smack town sh...   \n",
       "4                                        clear queue   \n",
       "\n",
       "                         phrase_stem_emoticon_unique  \\\n",
       "0     aircondit price point love place ca wait visit   \n",
       "1  soup dri laksa fri rice fri chicken wing brown...   \n",
       "2       snake queue intimid long co move fairli fast   \n",
       "3  yong tau foohidden circular road smack town sh...   \n",
       "4                                        clear queue   \n",
       "\n",
       "                        phrase_lemma_emoticon_unique  label  \\\n",
       "0  airconditioned price point loving place ca wai...    1.0   \n",
       "1  soup dry laksa fried rice fried chicken wing b...    1.0   \n",
       "2  snaking queue intimidated long co move fairly ...   -1.0   \n",
       "3  yong tau foohidden circular road smack town sh...    0.0   \n",
       "4                                        clear queue    1.0   \n",
       "\n",
       "                                     polarity_scores  \n",
       "0  {'neg': 0.0, 'neu': 0.642, 'pos': 0.358, 'comp...  \n",
       "1  {'neg': 0.063, 'neu': 0.663, 'pos': 0.274, 'co...  \n",
       "2  {'neg': 0.293, 'neu': 0.707, 'pos': 0.0, 'comp...  \n",
       "3  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "4  {'neg': 0.0, 'neu': 0.278, 'pos': 0.722, 'comp...  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainval[\"polarity_scores\"] = trainval.phrase_emoticon_generic.map(lambda phrase : sid.polarity_scores(phrase))\n",
    "test[\"polarity_scores\"] = test.phrase_emoticon_generic.map(lambda phrase : sid.polarity_scores(phrase))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval[\"compound\"] = trainval[\"polarity_scores\"].map(lambda score_dict : score_dict[\"compound\"])\n",
    "test[\"compound\"] = test[\"polarity_scores\"].map(lambda score_dict : score_dict[\"compound\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval[\"prediction\"] = trainval[\"compound\"].map(lambda c: 1 if c >0 else 0 if c == 0 else -1)\n",
    "test[\"prediction\"] = test[\"compound\"].map(lambda c: 1 if c >0 else 0 if c == 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Sentiment Analysis Model\n",
      "TrainingValidation Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0     0.4911    0.3303    0.3950       333\n",
      "         0.0     0.6190    0.6467    0.6325       917\n",
      "         1.0     0.7500    0.7913    0.7701      1236\n",
      "\n",
      "    accuracy                         0.6762      2486\n",
      "   macro avg     0.6200    0.5894    0.5992      2486\n",
      "weighted avg     0.6670    0.6762    0.6691      2486\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0     0.5263    0.3846    0.4444       104\n",
      "         0.0     0.5532    0.7156    0.6240       218\n",
      "         1.0     0.8129    0.7483    0.7793       453\n",
      "\n",
      "    accuracy                         0.6903       775\n",
      "   macro avg     0.6308    0.6162    0.6159       775\n",
      "weighted avg     0.7014    0.6903    0.6907       775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(\"VADER Sentiment Analysis Model\")\n",
    "print(\"TrainingValidation Data\")\n",
    "print(classification_report(trainval.label,trainval.prediction,digits=4))\n",
    "print(\"Test Data\")\n",
    "print(classification_report(test.label,test.prediction,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingValidation Data\n",
      "[[110 150  73]\n",
      " [ 71 593 253]\n",
      " [ 43 215 978]]\n",
      "Test Data\n",
      "[[ 40  33  31]\n",
      " [ 15 156  47]\n",
      " [ 21  93 339]]\n"
     ]
    }
   ],
   "source": [
    "print(\"TrainingValidation Data\")\n",
    "print(confusion_matrix(trainval.label,trainval.prediction))\n",
    "print(\"Test Data\")\n",
    "print(confusion_matrix(test.label,test.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['laksa approx small kind laksa eat',\n",
       "       'laksa lemak rice noodles cut small pieces feels weird genius bowl otah otah laksa',\n",
       "       'expect laksa taste good not exceptional sadly waste money taste good not exceptional sadly waste money',\n",
       "       'small portion', 'felt kinda pricey kinda pricey portion',\n",
       "       'small small bowl', 'air conditioning coild barely felt',\n",
       "       'katong laksa bowl mediocre katong laksa', 'laksa laksa small',\n",
       "       'expensive icecream',\n",
       "       'sharing different scoops ice cream waffle buttermilk matcha red velvet bud confused sharing different scoops ice cream',\n",
       "       'pricey cake larger',\n",
       "       'toastvisited popular coffee stall high expectations tad stale dry kaya slightly sweet',\n",
       "       'shiok price increase abit sian',\n",
       "       'floss banh mistill hungry serving portion small',\n",
       "       'soup salty oily beef dry surprising pho vietnamese tasted better',\n",
       "       'tasting platter definitely not worth og price barely',\n",
       "       'truffle fries tasted bland salmon fishy overcooked steak okay sauces meh burpple burrplesg surfandturf steak',\n",
       "       'lemonmeringuetart small',\n",
       "       'main course sought cheese room ingredients fish little overcooked ingredients fish little overcooked',\n",
       "       'truffle ftw cooked never right',\n",
       "       'came pretty small pot soup rice', 'smaller', 'hand disappointing',\n",
       "       'pretty small cup price', 'small pale pink',\n",
       "       'yummy pity portion small',\n",
       "       'cakesadly disappointing usually love bakes cake dry relatively bland topped meringue',\n",
       "       'told slow order saying',\n",
       "       'meringue tart devoid carpenter cook petite passionfruit admittedly not favourite table little senseless',\n",
       "       'lacked tartness curd',\n",
       "       'lava cake ps chicken steak pasta portions smaller',\n",
       "       'ordered mac cheese seafood pizza chicken cheesesteak sandwich chocolate lave cake cheesy sausage great disappointment',\n",
       "       'setsusing burpple expensive expensive',\n",
       "       'wagyu rib eye setordered burpple said no good spread vegetables soup tasty salty salty said no good spread vegetables soup tasty salty',\n",
       "       'slices',\n",
       "       'steamed pork spare ribs black bean sauce got briny slabs bathing oily broth muster tender fatty palpably absent unsurprising',\n",
       "       'little meat', 'salted egg prawntoo oily little salted salted egg',\n",
       "       'fell short watery egg blanket mixing chicken onion slices untidily salty soy sauce marination',\n",
       "       'comes size rice bowl fell short', 'long time long time long time',\n",
       "       'small serving tab small', 'pretty normal sizing half portion',\n",
       "       'occupied tables lunchtime', 'occupied tables lunchtime',\n",
       "       'occupied tables lunchtime wait',\n",
       "       'icecream premium category felt tasted pretty regular',\n",
       "       'looks small oversized palm substantial', 'good not breath',\n",
       "       'perennial long queue perennial long queue', 'overpriced small',\n",
       "       'better service staff attitude good better service staff attitude good',\n",
       "       'hong kiat seafood restaurant crab bee broth lacked depth',\n",
       "       'char siew read pin wei cheong fun good reviews unnaturally sweet soy sauce clinged tastebuds',\n",
       "       'snaking queue looked like', 'prepared queue',\n",
       "       'looked small portion ended nice',\n",
       "       'fried rice feel tad underseasoned', 'small chicken additional',\n",
       "       'small', 'sweet salmon plain no sauce',\n",
       "       'raw quail egg special sauce tastes heavily soy better sweetness expect better variety quality ingredients',\n",
       "       'smaller portion', 'decent portion small size',\n",
       "       'chewy albeit small tender chewy albeit small',\n",
       "       'legit portion noodles little small',\n",
       "       'slightly pricey alright location', 'smallest portion',\n",
       "       'glory mozzarella zinger meal spicy promised cheese pull came high charred bacon overly browned block immediately apparent patty burnt batter deconstructed burger',\n",
       "       'satisfying points portion bit small',\n",
       "       'truffle friestruffle fries lackluster extent ask extra',\n",
       "       'usually mins hour queue', 'look queue', 'little pricey',\n",
       "       'little pricey brownie good pricey brownie good', 'portion small',\n",
       "       'slight min wait', 'waiting food queue starts form outside',\n",
       "       'barbecued pork sweet savoury sauce drizzled honey glazed signature roast duck crispy london snow bun baked bbq buns wanton noodles mediocre',\n",
       "       'way overpriced', 'took long', 'looks like turn mouldy',\n",
       "       'lacking meat not juicy flavourful', 'cheaper high price',\n",
       "       'congeefew slices fatty duck meat',\n",
       "       'london roast duck skin glistening sauce mediocre plum dipping chewy meat costs london roast duck mediocre plum dipping chewy meat costs',\n",
       "       'worth queue', 'expensive mcgriddles cost',\n",
       "       'crunchy bits similar green tea matcha soft serve plain taste hot fudge sundae',\n",
       "       'snaking queue city hall',\n",
       "       'fluffy pricey compared bakeries standard', 'ok not cheap',\n",
       "       'shioyaki pricey', 'price lunch ouch', 'guess waiting',\n",
       "       'tasteless feistiest crumbs cheese not', 'short ribs steak chewy',\n",
       "       'snaking queue', 'little pricey',\n",
       "       'chicken tomyam soup clear nakhon kitchen bedok new months previous known nangfa thai tried favourite dishes way spicy',\n",
       "       'mind long ish wait lunchtime', 'actually enjoyed cup nt big',\n",
       "       'ni ginko nutsadly purely yam cake',\n",
       "       'took long time serve abt mins', 'usually long queues',\n",
       "       'vodka barely taste vodka taste',\n",
       "       'spicy miso special topping place chinatown point sells affordable reliable ramen mazesoba rich bit gelat like tonkotsu boiled eggs radish kimchi',\n",
       "       'unbearably spicy ordered regular level spice',\n",
       "       'tasteless squid non',\n",
       "       'lacks gravy typically reminiscent prawn noodles',\n",
       "       'packed dinner time', 'not',\n",
       "       'matcha taste way mild liking like milo drink hot coconut chocolate',\n",
       "       'becareful lunch time crowd', 'lacked wok hei taste',\n",
       "       'wary price portions', 'little pricey',\n",
       "       'not spicy based sauce spice', 'service slow quiet', 'wait long',\n",
       "       'romaine lettuce tomatoes dressed parmesan cheese thousand island dressing dissapointed type salad',\n",
       "       'sambal fish serving small', 'good post', 'brace long queue',\n",
       "       'long queue', 'bit small buy portion', 'spot queue',\n",
       "       'sat evening waiting time super long',\n",
       "       'beef bone soup felt creamy saltier like', 'better ambience',\n",
       "       'warm hot chocolate starbuckssg rainy weekend initial taste bit heavy linger longer not overwhelmed kouignamann pastry',\n",
       "       'crowded staff',\n",
       "       'soya sprouts thank god noodles salty preserved meats flavour',\n",
       "       'not hungry hungry', 'need wait long waited rib',\n",
       "       'serving time crowded went slow serving time crowded went',\n",
       "       'swiss rolls box usually huge chocoholic surprised chocolate ultimately tastes flat not good black sesame awesome',\n",
       "       'higher price higher price cheaper',\n",
       "       'ha cheong gai curry rice signature ikan ibilis onsen egg white curry sauce plain',\n",
       "       'brave long queues',\n",
       "       'sweet corn chicken breast bit tough complaint rich pastamania tea party creamy pasta tasty customization ingredients makes nicer',\n",
       "       'little expensive', 'come priced maybe cheaper',\n",
       "       'missing delicious nasi', 'pretty average pricey swiss rolls',\n",
       "       'faint cream tasted synthetic', 'decent pricey',\n",
       "       'charge kind pricey',\n",
       "       'sweet vanilla cotton candy white grapes green apple oaky bitter oranges',\n",
       "       'little lunch time super crowded',\n",
       "       'rip charge price seafood cream pasta originally',\n",
       "       'watery bland matcha', 'comes small serving scallops felt',\n",
       "       'small', 'look kinda small paltry size sized main', 'small',\n",
       "       'long wait', 'long queue', 'normal tea albeit pricey',\n",
       "       'super long queues watch video review snaking queue opening pm',\n",
       "       'snaking queue forms opens',\n",
       "       'vibes bit overpriced vibes bit overpriced',\n",
       "       'took way long grillgood food serving took way long long',\n",
       "       'kleftiko meal redeemed somewhat lacklustre starters baby soft slow roasted lamb served moreish tasting taste',\n",
       "       'expensive', 'portions little', 'never recommending place',\n",
       "       'pricey size', 'chopped small chopped small unbreakable',\n",
       "       'long long', 'bean curd small bean curd small tip',\n",
       "       'started ok halfway fishiness like shellfish', 'smaller cup',\n",
       "       'high', 'chargeable tap water final price',\n",
       "       'taste somewhat bland lacking taste somewhat bland lacking',\n",
       "       'ending meal pricey ending meal pricey ending meal pricey',\n",
       "       'higher', 'heavy chaota taste ordered plate chicken wing',\n",
       "       'wagyu beef burger wagyu fries undercooked',\n",
       "       'like overrated bland', 'overpriced pasta',\n",
       "       'mocha orange brioche underwhelming toasted bread drinking coffee',\n",
       "       'mediocre tasting definitely not worth cost',\n",
       "       'rings fatburger thought pretty underwhelming compared hype real onion batter tasted like overfried refried serving hard getting burger set refried serving hard',\n",
       "       'small portion', 'portion small portion', 'bit pricey',\n",
       "       'salmonfelt portion small bigger salmonfelt portion small',\n",
       "       'decent tasting bit pricey given', 'longest time',\n",
       "       'portions small small price portions small',\n",
       "       'small salad regular portion smaller comes small salad',\n",
       "       'stuck like microwaved food', 'okay portion size small',\n",
       "       'service brusque',\n",
       "       'zingera bit sickening slightly acceptable double tasted like cheese sticks pizza chains',\n",
       "       'wrap breaks heart bland watery instead tasty remotely like coleslaw purple cabbage sandwich tuna',\n",
       "       'bread butter pudding return bite ran vanilla sauce suppose plain cream coconut fans know simply not work',\n",
       "       'charging service charge', 'chilled long time',\n",
       "       'not properly defrosted served cut chocolate way sweet',\n",
       "       'smaller plumper', 'small portions meat monotonous',\n",
       "       'kebabs amd pretty expensive',\n",
       "       'left heart super fail sweetandsalty chocolate',\n",
       "       'katsu felt tongue tingle gelat ness comes soup drink dessert tongue tingle',\n",
       "       'spicy japchae ordered meh mushroom dish sesame oil strong raw carroty taste better dropped army stew mushroom dish sesame oil strong raw carroty taste',\n",
       "       'overpaid', 'overcooked small',\n",
       "       'chunks small not firm chunks small not firm',\n",
       "       'small chirashi bowl assorted sushi small chirashi bowl',\n",
       "       'small curry small', 'chewy small', 'given little',\n",
       "       'sobadipping sauce salty expected hot soba water dilute soup inside diff beef nanban',\n",
       "       'average singaporean dish tonkotsu ramen price soup base oily lacking flavours taste average singaporean dish tonkotsu ramen price',\n",
       "       'salted egg yolk saucenewly fried rice impressive pile vegetable bits lacked seasoning tasteless',\n",
       "       'long came chilli crab ramen good',\n",
       "       'including service charge pricey pricey including service charge pricey',\n",
       "       'brown sugar black tea oatlypriced clearly non existent flavour oatly milk',\n",
       "       'small'], dtype=object)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine wrong class -1\n",
    "trainval.loc[(trainval.label == -1) & (trainval.prediction != -1)].phrase.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Update Lexicon Dictionary (Round 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_food = {\n",
    "    \"tender\" : 4,\n",
    "    \"fresh\" : 4,\n",
    "    \"soggy\" : -4,\n",
    "    \"jelat\" : -4,\n",
    "    \"oily\" : -4,\n",
    "    \"overcooked\" :-4,\n",
    "    \"dry\" : -2,\n",
    "    \"disappointed\" : -4  \n",
    "}\n",
    "\n",
    "new_time = {\n",
    "    \"long queue\" : -4,\n",
    "    \"queue\" : -4,\n",
    "    \"wait\" : -2,\n",
    "    \"slow\" : -4,\n",
    "    \"crowd\" : -4\n",
    "}\n",
    "\n",
    "new_price = {\n",
    "    \"pricey\" : -4,\n",
    "    \"expensive\" : -4,\n",
    "    \"cheap\" : 4,\n",
    "    \"worth\" : 4,\n",
    "    \"overpriced\" : -4,\n",
    "    \"not worth\" : -4,\n",
    "    \"value for money\" : 4\n",
    "    \n",
    "}\n",
    "\n",
    "new_portion = {\n",
    "    \"small\" : -4,\n",
    "    \"large\" : 4,\n",
    "    \"generous\" : 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid.lexicon.update(new_food)\n",
    "sid.lexicon.update(new_time)\n",
    "sid.lexicon.update(new_price)\n",
    "sid.lexicon.update(new_portion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval[\"polarity_scores1\"] = trainval.phrase_emoticon_generic.map(lambda phrase : sid.polarity_scores(phrase))\n",
    "test[\"polarity_scores1\"] = test.phrase_emoticon_generic.map(lambda phrase : sid.polarity_scores(phrase))\n",
    "trainval[\"compound1\"] = trainval[\"polarity_scores1\"].map(lambda score_dict : score_dict[\"compound\"])\n",
    "test[\"compound1\"] = test[\"polarity_scores1\"].map(lambda score_dict : score_dict[\"compound\"])\n",
    "trainval[\"prediction1\"] = trainval[\"compound1\"].map(lambda c: 1 if c >0 else 0 if c == 0 else -1)\n",
    "test[\"prediction1\"] = test[\"compound1\"].map(lambda c: 1 if c >0 else 0 if c == 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Sentiment Analysis Model (Tuned with new words)\n",
      "TrainingValidation Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0     0.5450    0.6366    0.5873       333\n",
      "         0.0     0.6824    0.6140    0.6464       917\n",
      "         1.0     0.7649    0.7872    0.7759      1236\n",
      "\n",
      "    accuracy                         0.7031      2486\n",
      "   macro avg     0.6641    0.6793    0.6699      2486\n",
      "weighted avg     0.7050    0.7031    0.7029      2486\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0     0.5766    0.6154    0.5953       104\n",
      "         0.0     0.5961    0.6972    0.6427       218\n",
      "         1.0     0.8337    0.7528    0.7912       453\n",
      "\n",
      "    accuracy                         0.7187       775\n",
      "   macro avg     0.6688    0.6885    0.6764       775\n",
      "weighted avg     0.7324    0.7187    0.7231       775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(\"VADER Sentiment Analysis Model (Tuned with new words)\")\n",
    "print(\"TrainingValidation Data\")\n",
    "print(classification_report(trainval.label,trainval.prediction1,digits=4))\n",
    "print(\"Test Data\")\n",
    "print(classification_report(test.label,test.prediction1,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['instead went pig congee lo mai kai crystal dumplings total damage food photo rice normal sticky glutinous like not salty lomaikai porridge time stick congee smooth criminal bonus not salty',\n",
       "       'laksadelicious laksa', 'cravings laksa goes signature katong',\n",
       "       'laksa onsen egglovely edition egg', 'big laksa',\n",
       "       'waiting time no waiting waiting time no waiting',\n",
       "       'friday pig intestines big', 'good coffee sg good coffee sg',\n",
       "       'affordable utilising burpple',\n",
       "       'clay pot medium sauce dried chili slices ginger cloves mushy garlic heavenly supposed soggy decent dish overall',\n",
       "       'attentive', 'reasonably priced portion', 'small price',\n",
       "       'affordable option affordable option', 'runny beef patty juicy',\n",
       "       'west burger patty little bit overdone rings crispy left long time addictive ordinary left long time addictive finish eating ingredients addictive finish eating',\n",
       "       'came returned steak', 'tangy appetising',\n",
       "       'goodnesstaste double boiled soup boiled soup',\n",
       "       'chi soup set came mama flavourslovely dishes',\n",
       "       'har cheong kai chicken prawn paste ranks good ones bloody tasty juicy meat dry',\n",
       "       'balls bit pricey shiok dinner singapore crazy hot weather ordered blackball cold chinchow base bouncy chewy sweet potato red bean yum pearl refreshing shiok dinner singapore crazy hot weather ordered blackball',\n",
       "       'potatoesi starter botanico fried potato cubes nice bite oily duck meat',\n",
       "       'roasted balsamic favourite', 'right',\n",
       "       'buying bread stall admit garlic tasty',\n",
       "       'reasonable price came reasonable price',\n",
       "       'favourite tartspassionfruit meringue tart maldon sea salt caramel favourite tartspassionfruit meringue tart chocolate maldon',\n",
       "       'no additional gst service charge no additional gst service charge',\n",
       "       'sea salt tartfinally visit cool small menu worthy bakes nice tart crunchy crust weak small menu worthy bakes small menu worthy bakes',\n",
       "       'chill weekend feel not bustling people lattegreat place stop chill weekend feel not bustling people',\n",
       "       'no additional gst service charge no additional gst service charge',\n",
       "       'prices reasonable reasonable prices reasonable prices reasonable',\n",
       "       'prices reasonable reasonable prices reasonable prices reasonable',\n",
       "       'prices reasonable reasonable prices reasonable prices reasonable',\n",
       "       'prices reasonable reasonable prices reasonable prices reasonable',\n",
       "       'taste prridge fr dinner yesterday plain congee soya sauce chicken steamed pork rib dim sum vegetable claypot crystaljade crystaljadekitchen foodporn',\n",
       "       'braised pork rice bowl tasty watercress soup',\n",
       "       'read lot good stuff donya feed excited try honestly worst meals mentai salmon chicken katsu hopelessly bland average read lot good stuff donya feed worst meals katsu dons seasoned read lot good stuff donya feed honestly worst meals',\n",
       "       'affordable',\n",
       "       'fried salmon decent extremely affordable prices donya maki salmon mentai',\n",
       "       'big fat slice', 'decent extremely affordable prices',\n",
       "       'decent price', 'mochivery chewy fragrant',\n",
       "       'salted egg chicken waffle smoked salmon rosti decent',\n",
       "       'gravy starchy flavourful noodles able boiled egg chicken meat gravy',\n",
       "       'served quickly nonexistent queue bowl gets served quickly',\n",
       "       'looks small oversized palm substantial hides ichigo strawberry gone cheese cakes',\n",
       "       'lemon tart tried lemon tarts previously igsg eating lemon tarts previously igsg',\n",
       "       'fried rice good grilled squid teriyaki cod tasty overpriced small offer beer promotions fried rice good',\n",
       "       'affordable',\n",
       "       'roast meat char siewi told cantonese owner closed times visited today open decent chunky crispy skin',\n",
       "       'skillfully deliver plate', 'mentaiko sauce complemented',\n",
       "       'prawn mee soupfrom jalan sultan decent portion small add paprika powder enjoy coffee',\n",
       "       'prawn mee legit portion noodles little small prawnmee seafood',\n",
       "       'air conditioning staff',\n",
       "       'yong tau fu chye por sauce returned standalone ytf specialist eatery today decided preserved radish fragrant gravy chopped garlic went ed brinjal plain rice better fit',\n",
       "       'yong tau foothis slightly pricey quality ingredients',\n",
       "       'turtle soup chinatown complex food centrethey use base black chicken fragrant',\n",
       "       'fried sotong cutlet oozing egg yolk', 'decent portion',\n",
       "       'rem stall recommended queue start not bad fantastic soup recommended queue start not bad fantastic',\n",
       "       'value money not dim sum place located coffeeshop ang mo kio block menu',\n",
       "       'located coffee shop served decent', 'never resist lure carrot',\n",
       "       'favourite salad place eat dried tofu skin favourite salad place eat',\n",
       "       'crowded bowlawesome salad',\n",
       "       'savouring chocolate lemuelchocolate small batch bean bar tea selection galaxy lady earl grey savouring chocolate lemuelchocolate small batch bean bar',\n",
       "       'bak kut teh craving pork bone soup eating teochew peppery version went google handmade noodles frog leg porridge cooked dark soya sauce dried cuttlefish savoury eat rice',\n",
       "       'additional portion glaze', 'carrot cake nt bad crispy',\n",
       "       'decent meats inside',\n",
       "       'grilled pork combo rice decent passable meat need flavour crunch outside',\n",
       "       'ricetasty roasted chicken fluffy bitter gourd soup brewed coffee brewed coffee',\n",
       "       'fried chicken wing added slice luncheon meat infused fluffy rice red chilli sauce brings ingredients tasty meal brings ingredients tasty',\n",
       "       'belly ricearomatic roasted blend kopi watercress soup tasty savoury char siew roast meat rice',\n",
       "       'chef signature dish laksa fried rice normmmmm fragrant pour laksa gravy chilli',\n",
       "       'queue yay', 'hot rsti crispy outside',\n",
       "       'comes texture ramen marutama consistent providing al dente toppings',\n",
       "       'chicken broth unlike usual tonkotsu typically oily salty drink feeling egg molten yolk moss instead typical crispy type turns soggy nice touch marutama ramen chicken broth',\n",
       "       'double samurai beef sinful fries nomnomnom never tasted better long burgers sinful',\n",
       "       'got meat platters price',\n",
       "       'pork belly plus peppered chilli taste vs typical roasted chinese spanish style order dish',\n",
       "       'tries interact customers',\n",
       "       'place work drinks chilli visited saturday night place work drinks chilli visited saturday night work drinks chilli visited saturday night',\n",
       "       'dry portions good buffet', 'big piece cod',\n",
       "       'taste coconut water neutralises gelat effect makes refreshing flesh nom',\n",
       "       'chicken leg fried tau kwa rice doused piquant curry gravy fiery hot sambal belacan die love',\n",
       "       'yogurt ice creamthis refreshing sides added', 'gigantic',\n",
       "       'copious amounts nutella',\n",
       "       'grilled pork neck flopped dish moo manao tasty',\n",
       "       'looking like noodle fool noodles actually look chinese version mee kia springy al dente cooked egg tangly taste buds',\n",
       "       'handmade noodles smooth chewy black soybean paste starchy sauce not grainy',\n",
       "       'loaded onions', 'reasonable price', 'priced lots ingredients',\n",
       "       'priced lots ingredients', 'fried egg cabbage',\n",
       "       'juicy popiah start', 'tasting affordable', 'polite service',\n",
       "       'truffle bikini melt mouth bite sandwiched truffle confit piquillo puquillo peppers not spicy good try spicy',\n",
       "       'sticky date toffee puddingi learnt sauce not overwhelmingly sweet scoop vanilla ice cream sticky date',\n",
       "       'sells affordable reliable ramen mazesoba', 'cozy little joint',\n",
       "       'fat chunks chicken laced', 'absolutely steal value',\n",
       "       'double chocolate walnut muffinamazing forget pie',\n",
       "       'herbal mutton soup alan banana leaves bbq seafood',\n",
       "       'right not wet',\n",
       "       'fried rice thai food fragrant flavourful bits chicken meat thai food',\n",
       "       'choices available menu frame sambal seafood bruschetta drink slices pizza try',\n",
       "       'cakenubbad coffee neighbourhood joint left feeling undecided',\n",
       "       'espresso milkshake',\n",
       "       'dirty bun offered croissant weekend sinful good sinful good',\n",
       "       'cakehappy national', 'mentioned no gst service charge',\n",
       "       'coconut taste instantly hits mellow bitter coconut taste instantly hits mellow bitter',\n",
       "       'breadfragrant fluffy',\n",
       "       'gamberoni pizza express favourite dish order incredibly flavourful garlic aglio olio base juicy prawns halfeatenblog pizzaexpress pasta',\n",
       "       'lots liao',\n",
       "       'balanced meal flavorful need dressing corn shredded cabbage not',\n",
       "       'scenic view gardens bay form', 'packed', 'attentive',\n",
       "       'beef hidden gem located new kap mall flavourful broth paired chewy rice noodles fried garlic beef slices',\n",
       "       'hefty', 'authentic boat noodles pick beef pork protein different',\n",
       "       'mee kia simplicity glorious', 'ingredients', 'ingredients cent',\n",
       "       'bad reasonable price', 'piece',\n",
       "       'oysters juicy succulent meat sandwiched focaccia spicy remoulade sauce goes seafood dishes mayonnaise adds right',\n",
       "       'dig bowl bcm soup oops dry version wanton mee nice bite overcooked like stalls pretty tasty',\n",
       "       'filled ingredients',\n",
       "       'tasty pork meat taste white black ordinary wanton noodle',\n",
       "       'shakemeister dog picked hotdog bun option topped crispy marinated shallots evolutionary taste burger',\n",
       "       'favourite place', 'brings friday night new level satay beer',\n",
       "       'white carrot cake plus',\n",
       "       'milk tea choc cakethis soft fluffy cake thicker',\n",
       "       'boozy black forest layers incredibly moist chocolate sponge cake held silky smooth whipped cream filled kirsch',\n",
       "       'big pieces', 'quick service', 'super breast slow cooked soft',\n",
       "       'average noodle not flavourful',\n",
       "       'night hokkaido style small slab butter soup black pig corn tamago seaweed enjoyed especially small slab butter soup',\n",
       "       'braised charcoal tofu located intersection figaro street jalan tua kong tasty court serves refined modern chinese zhi char real quality fried rice roe jackfruit chili crab',\n",
       "       'soft fluffy', 'fat nuts', 'aromatic broth spice notes',\n",
       "       'add anymore salt salmon gave balanced taste',\n",
       "       'note restaurant pricey', 'additional sausage',\n",
       "       'favourite salad shop meat toppings mesclun leaves choose meat topping remembered correctly',\n",
       "       'affordable',\n",
       "       'prawn aglio set nus students staff finally new food place nus spice comes pasta prawn aglio garlicky oily',\n",
       "       'mie ayam jamur bakso mie noodle soup beef ball available toktoksg somerset seasoning looked simple noodles addictive tasty',\n",
       "       'noms', 'glutinous ricelove onion fried chilli paste comes',\n",
       "       'larger size', 'decent',\n",
       "       'orrechiette pasta wagyu ragu scaglie di parmigiana melanzane grigliate ricotta little twisted grilled eggplant capocollo dop burrata tomato datterino cheese bursts impact paired juicy sliced cherry tomatoes romaine lettuce simply oh',\n",
       "       'loaded seafood dish',\n",
       "       'affordable price probably affordable stalls pricing dishes price probably',\n",
       "       'haebi mushy flavourful', 'flavourful sauce',\n",
       "       'kaya toast soft boiled eggsas hits spot coconut jam hot beverage dishes locals favourite come breakfast tea black soy sauce thinly sliced bread chilled butter',\n",
       "       'kaya toast setca wrong combo hearty singapore style breakfast coffee consistently good',\n",
       "       'pepper frymy favourite dish night bursting umami soaked sauce bowl incredibly flavourful paired naan wholesome',\n",
       "       'favourite cookie sauce',\n",
       "       'favourite cookie sauce makandaydream yole yolesg yogurt',\n",
       "       'queue fast come early queue',\n",
       "       'handmade soup flavourful favourites stall specialises ytf',\n",
       "       'old gyudon yoshinoya lunch brown rice option refreshing green tea piping hot miso soup',\n",
       "       'miss salmon sashimi prawn decorate eevarh',\n",
       "       'good vibes bit overpriced',\n",
       "       'filled assortment ingredients salted almond nuts tender mock meat stealing',\n",
       "       'dips spicy sheep feta cheese spread chillis roasted eggplant banana peppers simmered olive oil pita bread usual salad combination avocado balsamico orange dressing non gamey new zealand lamb marinated slow till tender strong grilled smokiness slow grilling burning charcoal flaky pastry held',\n",
       "       'liberal amounts pineapple', 'overwhelming',\n",
       "       'crunchy pistachio biscuit smooth not strong taste fresh',\n",
       "       'offers affordable', 'shorter queue', 'decent price',\n",
       "       'crispy fish soft succulent aromatic bite potato salad egg salad mayo sauce meal chunks pretty tough think overcooked',\n",
       "       'nice experience bad not able appreciate service',\n",
       "       'norwegian salmon foie gras sea plump juicy dark horse opens phase',\n",
       "       'deep fried yam moreish meat mushroom mix drunk food saucy pork point mildly sinful oh hell yeah',\n",
       "       'brown sugar bubble teathis probably cheapest affordable famous brand affordable price',\n",
       "       'individual portion reasonable size individual portion reasonable size',\n",
       "       'staffed staff generally attentive', 'big pieces',\n",
       "       'squid ink pasta venue cosy place head cosy place head',\n",
       "       'favourite laksa cos gravy scallop laksa changed normal',\n",
       "       'slight coconut fragrant',\n",
       "       'grilled iberico tasting pork chop far satisfying portion perfectly cook not dry hard meat small slice raisins not dry hard meat better apple small slice raisins slow grilled iberico porkprince range dish rating freshness slow grilled iberico porkprince range dish rating freshness',\n",
       "       'mushroom savory garlic bread', 'belly',\n",
       "       'high quality grain fed angus wagyu products culinary australian meat branded beef premium',\n",
       "       'ramentenderlious pork light tasty soup base',\n",
       "       'battered squid lavishly coated chopped parsley sea salt served mayonnaise enhanced',\n",
       "       'soooo affordable makes wan na soooo affordable makes wan na',\n",
       "       'belly stewelegant dcor especially upper floors african ambient music',\n",
       "       'pancakes cafe absolute favourite singapore far fantastic amazingly soft fluffy despite exterior softserve icecream rly milky not sweet nice chill atmosphere',\n",
       "       'tempura batter batter oily retaining satisfying crunch batter batter',\n",
       "       'sushithe tamago sushi seasoned rice', 'preeminent place heart',\n",
       "       'affordable breakfast midday tea snack',\n",
       "       'nice not exactly fantastic ice cream burpple add waffles nice not exactly fantastic',\n",
       "       'breaded salmon paella spice mix superbly seasoned fared near cereal ebi',\n",
       "       'justify long justify long queues',\n",
       "       'caught attention taste ordinary crushed oreo buns served oreos crumbs soil',\n",
       "       'playing head bartender edwin forte crafting culinary encapsulation char siu rice complete slice roasted pork staple chili sauce cut weight',\n",
       "       'bak kut teh broth bulleit rye balanced oolong syrup served tiao started serving cocktails',\n",
       "       'bulleit rye angostura bitters added chill come drink work', 'way',\n",
       "       'half price', 'came mins later', 'affordable big bowl',\n",
       "       'liao convenient eat',\n",
       "       'cheaper price cheaper price cheapest porridge',\n",
       "       'serving affordable lunch sets ofc situation telok ayer cbd crowd lazy walk tanjong pagar like affordable lunch sets ofc situation telok ayer cbd crowd lazy walk tanjong pagar like',\n",
       "       'small cosy ish vibe rly',\n",
       "       'grlic butter basil sauce good combination tad overcooked good combination greens',\n",
       "       'extra', 'quick quick meal transiting', 'quick', 'quick',\n",
       "       'filled timeless hongkong class safra yishun', 'rice',\n",
       "       'rendition favourite thai dish silky coated right',\n",
       "       'fried rice fried chicken pope jai thai scape popejaithai littlesweetbonsbons popejaithai',\n",
       "       'socialenterprise affordable',\n",
       "       'no queue no queue drop delicious creme brulee crust nice touch crunchy texture',\n",
       "       'truffle taste', 'know hard master chefs worked',\n",
       "       'use angoli fish threadfin bream high grade firm flaky time curryfishhead curry',\n",
       "       'peanut butter malted shakemy favourite milkshake incredibly addictive',\n",
       "       'beehoon minced meat fish makes flavourful', 'japanese soba lunch',\n",
       "       'breaded fish noodles right drenched assam gravy reminded laksa soft',\n",
       "       'grilled chicken chop accompanied pasta salad version spagtacular hit spot pax',\n",
       "       'seabassgenerous portion fish potatoes right right',\n",
       "       'affordable japanese food plus no svc charge affordable',\n",
       "       'panoramic view',\n",
       "       'spag aglio came decent quantity seafood freshness',\n",
       "       'choose portion want petite xtra wo waste money not finishing feel satisfied generous looks small',\n",
       "       'picked romaine lettuce choice carbs chicken breast seasoned roasted bell peppers cauliflower mushroom medley distasteful awhile soaked ingredients particularly oily toasted coconut flakes romesco sauce tasted good oil ingredients romaine particularly oily tasted good portions never fail return',\n",
       "       'quick bite breakfast coffee',\n",
       "       'pulled favourite slayerespresso machine beans',\n",
       "       'black truffle pork chop rice seafood pasta abalone langoustine bee hoon set includes appetiser try signature lobster porridge salted egg',\n",
       "       'decent place', 'unique tasty',\n",
       "       'ink mee tai mak minced pork alongside tobiko japanese flying fish roe followed black squiggly noodle like object hidden chinese noodles known silver needle rat noodle distinct flavours basil chilli blended create fiery unforgettable sensation incredibly smooth glides throat no time mouthful',\n",
       "       'flavourful peppery not overpowering', 'set soft'], dtype=object)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine wrong class 1\n",
    "trainval.loc[(trainval.label == 1) & (trainval.prediction1 != 1)].phrase.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Update Lexicon Dictionary (Round 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_food = {\n",
    "    \"tender\" : 2,\n",
    "    \"fresh\" : 2,\n",
    "    \"soggy\" : -2,\n",
    "    \"jelat\" : -2,\n",
    "    \"oily\" : -2,\n",
    "    \"overcooked\" :-2,\n",
    "    \"dry\" : -2,\n",
    "    \"disappointed\" : -2,\n",
    "    \"cravings satisfied\" : 2,\n",
    "    \"crispy\" : 2,\n",
    "    \"sinful\" : 2,\n",
    "    \"tough\" : -2,\n",
    "    \"cold\" : -2\n",
    "}\n",
    "\n",
    "new_time = {\n",
    "    \"long queue\" : -2,\n",
    "    \"queue\" : -2,\n",
    "    \"wait\" : -2,\n",
    "    \"slow\" : -2,\n",
    "    \"crowd\" : -2,\n",
    "    \"crowded\" : -2,\n",
    "    \"no waiting time\" : 2,\n",
    "    \"fast\" : 2,\n",
    "}\n",
    "\n",
    "new_price = {\n",
    "    \"pricey\" : -2,\n",
    "    \"expensive\" : -2,\n",
    "    \"cheap\" : 2,\n",
    "    \"worth\" : 2,\n",
    "    \"overpriced\" : -2,\n",
    "    \"not worth\" : -2,\n",
    "    \"value for money\" : 2,\n",
    "    \"reasonable\" : 2,\n",
    "    \"reasonably\" : 2,\n",
    "    \"affordable\" : 2,\n",
    "    \"steal\" : 2   \n",
    "}\n",
    "\n",
    "new_portion = {\n",
    "    \"small\" : -2,\n",
    "    \"large\" : 2,\n",
    "    \"generous\" : 2,\n",
    "    \"sufficient\" : 1,\n",
    "    \"enough\" : 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid.lexicon.update(new_food)\n",
    "sid.lexicon.update(new_time)\n",
    "sid.lexicon.update(new_price)\n",
    "sid.lexicon.update(new_portion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval[\"polarity_scores2\"] = trainval.phrase_emoticon_generic.map(lambda phrase : sid.polarity_scores(phrase))\n",
    "test[\"polarity_scores2\"] = test.phrase_emoticon_generic.map(lambda phrase : sid.polarity_scores(phrase))\n",
    "trainval[\"compound2\"] = trainval[\"polarity_scores2\"].map(lambda score_dict : score_dict[\"compound\"])\n",
    "test[\"compound2\"] = test[\"polarity_scores2\"].map(lambda score_dict : score_dict[\"compound\"])\n",
    "trainval[\"prediction2\"] = trainval[\"compound2\"].map(lambda c: 1 if c >0 else 0 if c == 0 else -1)\n",
    "test[\"prediction2\"] = test[\"compound2\"].map(lambda c: 1 if c >0 else 0 if c == 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Sentiment Analysis Model (Tuned with new words 2)\n",
      "TrainingValidation Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0     0.5562    0.6096    0.5817       333\n",
      "         0.0     0.7009    0.6031    0.6483       917\n",
      "         1.0     0.7605    0.8196    0.7889      1236\n",
      "\n",
      "    accuracy                         0.7116      2486\n",
      "   macro avg     0.6725    0.6774    0.6730      2486\n",
      "weighted avg     0.7111    0.7116    0.7093      2486\n",
      "\n",
      "Test Data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0     0.6400    0.6154    0.6275       104\n",
      "         0.0     0.6234    0.6835    0.6521       218\n",
      "         1.0     0.8349    0.8035    0.8189       453\n",
      "\n",
      "    accuracy                         0.7445       775\n",
      "   macro avg     0.6994    0.7008    0.6995       775\n",
      "weighted avg     0.7492    0.7445    0.7463       775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "print(\"VADER Sentiment Analysis Model (Tuned with new words 2)\")\n",
    "print(\"TrainingValidation Data\")\n",
    "print(classification_report(trainval.label,trainval.prediction2,digits=4))\n",
    "print(\"Test Data\")\n",
    "print(classification_report(test.label,test.prediction2,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7462961290322581"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.6275*(104/775) + (218/775)*0.6521 + (453/775)* 0.8189"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFold CV For Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_k_fold_VADER(column, data, model_name):\n",
    "    \n",
    "    # Generate fold predictions\n",
    "    fold_num = 1\n",
    "    for tf_combi in data:\n",
    "        train = tf_combi[0].copy() # no training needed for VADER \n",
    "        predict_on = tf_combi[1] \n",
    "\n",
    "        # Get Labels\n",
    "        train_label = train.label # not required\n",
    "        \n",
    "        # Fit Model\n",
    "        train[\"polarity_scores\"] = train[column].map(lambda phrase : sid.polarity_scores(phrase))\n",
    "        train[\"pos\"] = train[\"polarity_scores\"].map(lambda score_dict : score_dict[\"pos\"])\n",
    "        train[\"neg\"] = train[\"polarity_scores\"].map(lambda score_dict : score_dict[\"neg\"])\n",
    "\n",
    "        # Create Dataframe and output\n",
    "        df = pd.DataFrame(data=train[[\"neg\",\"pos\",\"label\"]].values, columns = [model_name+'_prob_neg', model_name+'_prob_pos',\"label\"])\n",
    "        # df.drop(columns= [model_name+'_prob_neu'])\n",
    "        ordered_cols = [model_name+'_prob_pos',model_name+'_prob_neg',\"label\"]\n",
    "        df=df[ordered_cols]\n",
    "        if fold_num <=5:\n",
    "            path = \"kfold/\" + model_name + '_fold' + str(fold_num) +'.csv'\n",
    "        else:\n",
    "            path = \"kfold/\" + model_name + '_test.csv'\n",
    "        \n",
    "        df.to_csv(path, index=False)\n",
    "        \n",
    "        fold_num +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "fold1 = pd.read_csv('stacking_folds/fold1.csv')\n",
    "fold2 = pd.read_csv('stacking_folds/fold2.csv')\n",
    "fold3 = pd.read_csv('stacking_folds/fold3.csv')\n",
    "fold4 = pd.read_csv('stacking_folds/fold4.csv')\n",
    "fold5 = pd.read_csv('stacking_folds/fold5.csv')\n",
    "\n",
    "# VADER DONT NEED\n",
    "train1 = pd.read_csv('stacking_folds/train1.csv')\n",
    "train2 = pd.read_csv('stacking_folds/train2.csv')\n",
    "train3 = pd.read_csv('stacking_folds/train3.csv')\n",
    "train4 = pd.read_csv('stacking_folds/train4.csv')\n",
    "train5 = pd.read_csv('stacking_folds/train5.csv')\n",
    "\n",
    "# VADER DONT NEED\n",
    "train_all = pd.read_csv('stacking_folds/train_all.csv')\n",
    "test = pd.read_csv('stacking_folds/test.csv')\n",
    "\n",
    "# store in suitable data structure\n",
    "data = [(fold1, fold1), (fold2, fold2),(fold3, fold3), (fold4, fold4), (fold5, fold5), (test, test)]\n",
    "\n",
    "column = \"phrase_emoticon_generic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_k_fold_VADER(column=column, data=data, model_name=\"VADER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save full model\n",
    "full_df = pd.read_csv(\"new_labels/ALL_LABELLED_DATA.csv\")\n",
    "\n",
    "full_df[\"polarity_scores\"] = full_df[column].map(lambda phrase : sid.polarity_scores(phrase))\n",
    "full_df[\"pos\"] = full_df[\"polarity_scores\"].map(lambda score_dict : score_dict[\"pos\"])\n",
    "full_df[\"neg\"] = full_df[\"polarity_scores\"].map(lambda score_dict : score_dict[\"neg\"])\n",
    "\n",
    "model_name = \"VADER\"\n",
    "# Create Dataframe and output\n",
    "df = pd.DataFrame(data=full_df[[\"neg\",\"pos\",\"label\"]].values, columns = [model_name+'_prob_neg', model_name+'_prob_pos',\"label\"])\n",
    "# df.drop(columns= [model_name+'_prob_neu'])\n",
    "ordered_cols = [model_name+'_prob_pos',model_name+'_prob_neg',\"label\"]\n",
    "df=df[ordered_cols]\n",
    "\n",
    "df.to_csv(\"fold_predictions/VADER/VADER_all.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_VADER_model(dataframe,column):\n",
    "    \"\"\"\n",
    "    This function loads the VADER model whose dictionary has been updated.\n",
    "    \n",
    "    :dataframe : data to be predicted\n",
    "    :column : column used for VADER to predict\n",
    "    \n",
    "    :rtype : dataframe with 2 columns containing prediction probability\n",
    "       \n",
    "    \"\"\"\n",
    "    import nltk\n",
    "    nltk.download('vader_lexicon')\n",
    "    from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    new_food = {\n",
    "        \"tender\" : 2,\n",
    "        \"fresh\" : 2,\n",
    "        \"soggy\" : -2,\n",
    "        \"jelat\" : -2,\n",
    "        \"oily\" : -2,\n",
    "        \"overcooked\" :-2,\n",
    "        \"dry\" : -2,\n",
    "        \"disappointed\" : -2,\n",
    "        \"cravings satisfied\" : 2,\n",
    "        \"crispy\" : 2,\n",
    "        \"sinful\" : 2,\n",
    "        \"tough\" : -2,\n",
    "        \"cold\" : -2\n",
    "    }\n",
    "\n",
    "    new_time = {\n",
    "        \"long queue\" : -2,\n",
    "        \"queue\" : -2,\n",
    "        \"wait\" : -2,\n",
    "        \"slow\" : -2,\n",
    "        \"crowd\" : -2,\n",
    "        \"crowded\" : -2,\n",
    "        \"no waiting time\" : 2,\n",
    "        \"fast\" : 2,\n",
    "    }\n",
    "\n",
    "    new_price = {\n",
    "        \"pricey\" : -2,\n",
    "        \"expensive\" : -2,\n",
    "        \"cheap\" : 2,\n",
    "        \"worth\" : 2,\n",
    "        \"overpriced\" : -2,\n",
    "        \"not worth\" : -2,\n",
    "        \"value for money\" : 2,\n",
    "        \"reasonable\" : 2,\n",
    "        \"reasonably\" : 2,\n",
    "        \"affordable\" : 2,\n",
    "        \"steal\" : 2   \n",
    "    }\n",
    "\n",
    "    new_portion = {\n",
    "        \"small\" : -2,\n",
    "        \"large\" : 2,\n",
    "        \"generous\" : 2,\n",
    "        \"sufficient\" : 1,\n",
    "        \"enough\" : 1\n",
    "    }\n",
    "\n",
    "    sid.lexicon.update(new_food)\n",
    "    sid.lexicon.update(new_time)\n",
    "    sid.lexicon.update(new_price)\n",
    "    sid.lexicon.update(new_portion)\n",
    "\n",
    "    \n",
    "    dataframe[\"polarity_scores\"] = dataframe[column].map(lambda phrase : sid.polarity_scores(phrase))\n",
    "    dataframe[\"pos\"] = dataframe[\"polarity_scores\"].map(lambda score_dict : score_dict[\"pos\"])\n",
    "    dataframe[\"neg\"] = dataframe[\"polarity_scores\"].map(lambda score_dict : score_dict[\"neg\"])\n",
    "\n",
    "    # Create Dataframe and output\n",
    "    df = pd.DataFrame(data=dataframe[[\"neg\",\"pos\",\"label\"]].values, columns = [model_name+'_prob_neg', model_name+'_prob_pos',\"label\"])\n",
    "    # df.drop(columns= [model_name+'_prob_neu'])\n",
    "    ordered_cols = [model_name+'_prob_pos',model_name+'_prob_neg',\"label\"]\n",
    "    df = df[ordered_cols]\n",
    "    path = \"stacking_predictions_\" + \"VADER.csv\"\n",
    "\n",
    "    df.to_csv(path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}