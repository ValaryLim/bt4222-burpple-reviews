{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hourly-impact",
   "metadata": {},
   "source": [
    "# Simple Transformers Model\n",
    "\n",
    "- Documentation: https://simpletransformers.ai/docs/binary-classification/\n",
    "- Model Types: https://simpletransformers.ai/docs/classification-specifics/#supported-model-types\n",
    "- Github: https://github.com/ThilinaRajapakse/simpletransformers\n",
    "- Tutorials:\n",
    "    - https://towardsdatascience.com/simple-transformers-introducing-the-easiest-bert-roberta-xlnet-and-xlm-library-58bf8c59b2a3\n",
    "    - https://medium.com/towards-artificial-intelligence/text-classification-with-simple-transformers-a29d13358135\n",
    "    - https://towardsdatascience.com/battle-of-the-transformers-electra-bert-roberta-or-xlnet-40607e97aba3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# model training\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.special import softmax\n",
    "\n",
    "# for display\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-pasta",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path and filenames\n",
    "path = 'data/new_unagg/'\n",
    "train = 'train'\n",
    "val = 'val'\n",
    "test = 'test'\n",
    "suffix = '_newpreproc_unagg.csv'\n",
    "\n",
    "# change this accordingly: 'phrase', 'phrase_lemma', 'phrase_stem'\n",
    "text_column = 'phrase_stem'\n",
    "old_new = 'new_preproc_unagg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data dict\n",
    "data = {}\n",
    "data_train = {}\n",
    "data_names = [train, val, test]\n",
    "\n",
    "for name in data_names:\n",
    "    # read data\n",
    "    df = pd.read_csv(path+name+suffix)\n",
    "    # convert to int type\n",
    "    df['label'] = df['label'].astype('int32')\n",
    "    # rename columns - requirement of the simpletransformers package\n",
    "    df = df.rename({'label': 'labels'}, axis=1)\n",
    "    df = df.rename({text_column: 'text'}, axis=1)\n",
    "    # add to data dict\n",
    "    data[f'{name}_{text_column}'] = df\n",
    "    # data for training - only 2 columns\n",
    "    df_train = pd.DataFrame(df[['text', 'labels']])\n",
    "    # convert -1 labels to 2 so the model recognises it\n",
    "    df_train['labels'] = df_train.apply(lambda x: int(x.labels), axis=1)\n",
    "    df_train['labels'] = df_train.apply(lambda x: 2 if x.labels == -1 else x.labels, axis=1)\n",
    "    data_train[f'{name}_{text_column}'] = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in data.items():\n",
    "    print(df_name)\n",
    "    print(df.shape)\n",
    "    print(df.labels.value_counts())\n",
    "    display(df.head(3))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train and val\n",
    "train_all = pd.concat([data['train_'+text_column], data['val_'+text_column]]) ##\n",
    "data['train_all_'+text_column] = train_all\n",
    "\n",
    "# combine train and val of only text and labels\n",
    "train_all = pd.concat([data_train['train_'+text_column], data_train['val_'+text_column]]) ##\n",
    "data_train['train_all_'+text_column] = train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['train_all_'+text_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-democrat",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['train_all_'+text_column].labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-lesbian",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lyric-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # load saved model\n",
    "    model_args = ClassificationArgs(num_train_epochs=2, learning_rate=5e-5)\n",
    "    model = ClassificationModel(model_type = 'bert', \\\n",
    "                                model_name = f'saved_models/bert_{old_new}_{text_column}', \\\n",
    "                                args = model_args, use_cuda = False)\n",
    "except:\n",
    "    # initialise model\n",
    "    model_args = ClassificationArgs(num_train_epochs=2, learning_rate = 5e-5, \\\n",
    "                                    output_dir = f'saved_models/bert_{old_new}_{text_column}')\n",
    "    model = ClassificationModel(model_type = 'bert', \\\n",
    "                                 model_name = 'bert-base-uncased', \\\n",
    "                                 num_labels = 3, \\\n",
    "                                 args = model_args, use_cuda = False)\n",
    "    # train the model\n",
    "    model.train_model(data_train['train_all_'+text_column])\n",
    "\n",
    "# other model_type & model_name combinations\n",
    "# bert & bert-base-uncased\n",
    "# electra & google/electra-base-discriminator\n",
    "# roberta & roberta-base\n",
    "# distilbert & distilbert-base-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-creator",
   "metadata": {},
   "source": [
    "## Predict on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "test_pred, test_raw_outputs = model.predict(data['test_'+text_column].text)\n",
    "\n",
    "# append prediction to df\n",
    "test_pred_df = data['test_'+text_column].copy()\n",
    "test_pred_df['raw_pred'] = test_pred\n",
    "# convert 2 back to -1\n",
    "test_pred_df['pred'] = test_pred_df.apply(lambda x: -1 if x['raw_pred'] == 2 else x['raw_pred'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = classification_report(test_pred_df.labels, test_pred_df.pred, output_dict=True)\n",
    "# save to txt\n",
    "f = open(f'model_results/bert/custom/{old_new}/test_{text_column}.txt', \"w\")\n",
    "f.write( str(test_results) )\n",
    "f.close()\n",
    "\n",
    "print(classification_report(test_pred_df.labels, test_pred_df.pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-andrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df.pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "# convert raw outputs to probabilities\n",
    "probabilities = softmax(test_raw_outputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-tuition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "handy-inclusion",
   "metadata": {},
   "source": [
    "# Prepare Predictions for Stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-theorem",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-county",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path and filenames\n",
    "path = 'data/stacking_folds/' # DO NOT CHANGE THIS\n",
    "text_column = 'phrase' # DO NOT CHANGE THIS\n",
    "\n",
    "# fold_num = 5 # \n",
    "\n",
    "# train_fold_names = [f'train{fold_num}', f'fold{fold_num}'] # DO NOT CHANGE THIS\n",
    "train_fold_names = ['train_all', 'test']\n",
    "suffix = '.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data dict\n",
    "data = {}\n",
    "data_train = {}\n",
    "\n",
    "for name in train_fold_names:\n",
    "    # read data\n",
    "    df = pd.read_csv(path+name+suffix)\n",
    "    # convert to int type\n",
    "    df['label'] = df['label'].astype('int32')\n",
    "    # rename columns - requirement of the simpletransformers package\n",
    "    df = df.rename({'label': 'labels'}, axis=1)\n",
    "    df = df.rename({text_column: 'text'}, axis=1)\n",
    "    # add to data dict\n",
    "    data[f'{name}'] = df\n",
    "    # data for training - only 2 columns\n",
    "    df_train = pd.DataFrame(df[['text', 'labels']])\n",
    "    # convert -1 labels to 2 so the model recognises it\n",
    "    df_train['labels'] = df_train.apply(lambda x: int(x.labels), axis=1)\n",
    "    df_train['labels'] = df_train.apply(lambda x: 2 if x.labels == -1 else x.labels, axis=1)\n",
    "    data_train[f'{name}'] = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in data.items():\n",
    "    print(df_name)\n",
    "    print(df.shape)\n",
    "    print(df.labels.value_counts())\n",
    "    display(df.head(3))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-spending",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # load saved model\n",
    "    model_args = ClassificationArgs(num_train_epochs=2, learning_rate=5e-5)\n",
    "    model = ClassificationModel(model_type = 'bert', \\\n",
    "                                model_name = f'saved_models/bert_{train_fold_names[-1]}', \\\n",
    "                                args = model_args, use_cuda = False)\n",
    "except:\n",
    "    # initialise model\n",
    "    model_args = ClassificationArgs(num_train_epochs=2, learning_rate = 5e-5, \\\n",
    "                                    output_dir = f'saved_models/bert_{train_fold_names[-1]}')\n",
    "    model = ClassificationModel(model_type = 'bert', \\\n",
    "                                 model_name = 'bert-base-uncased', \\\n",
    "                                 num_labels = 3, \\\n",
    "                                 args = model_args, use_cuda = False)\n",
    "    # train the model\n",
    "    # model.train_model(data_train[f'train{fold_num}'])\n",
    "    model.train_model(data_train['train_all'])\n",
    "\n",
    "# other model_type & model_name combinations\n",
    "# bert & bert-base-uncased\n",
    "# electra & google/electra-base-discriminator\n",
    "# roberta & roberta-base\n",
    "# distilbert & distilbert-base-cased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-welsh",
   "metadata": {},
   "source": [
    "## Predict on Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-recognition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "# fold_pred, fold_raw_outputs = model.predict(data[f'fold{fold_num}'].text)\n",
    "fold_pred, fold_raw_outputs = model.predict(data['test'].text) # train on train_all, test on test\n",
    "\n",
    "# append prediction to df\n",
    "#Â fold_pred_df = data[f'fold{fold_num}'].copy()\n",
    "fold_pred_df = data['test'].copy()\n",
    "fold_pred_df['raw_pred'] = fold_pred\n",
    "# convert 2 back to -1\n",
    "fold_pred_df['pred'] = fold_pred_df.apply(lambda x: -1 if x['raw_pred'] == 2 else x['raw_pred'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "# convert raw outputs to probabilities\n",
    "probabilities = softmax(fold_raw_outputs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_pred_df['bert_prob_pos'] = probabilities[:, 1]\n",
    "fold_pred_df['bert_prob_neg'] = probabilities[:, 2]\n",
    "# fold_pred_df.to_csv(f'stacking_preds/bert/bert_fold{fold_num}_full.csv', index=False)\n",
    "fold_pred_df.to_csv(f'stacking_preds/bert/bert_test_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_preds_only = fold_pred_df[['bert_prob_pos', 'bert_prob_neg']]\n",
    "# fold_preds_only.to_csv(f'stacking_preds/bert/bert_fold{fold_num}.csv', index=False)\n",
    "fold_preds_only.to_csv(f'stacking_preds/bert/bert_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(fold_pred_df.labels, fold_pred_df.pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_pred_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_pred_df.pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_preds_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-upgrade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-consent",
   "metadata": {},
   "source": [
    "# Train Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv('data/stacking_folds/ALL_LABELLED_DATA.csv')\n",
    "# convert to int type\n",
    "df['label'] = df['label'].astype('int32')\n",
    "# rename columns - requirement of the simpletransformers package\n",
    "df = df.rename({'label': 'labels'}, axis=1)\n",
    "df = df.rename({'phrase': 'text'}, axis=1)\n",
    "    \n",
    "df_train = pd.DataFrame(df[['text', 'labels']])\n",
    "# convert -1 labels to 2 so the model recognises it\n",
    "df_train['labels'] = df_train.apply(lambda x: int(x.labels), axis=1)\n",
    "df_train['labels'] = df_train.apply(lambda x: 2 if x.labels == -1 else x.labels, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # load saved model\n",
    "    model_args = ClassificationArgs(num_train_epochs=2, learning_rate=5e-5)\n",
    "    model = ClassificationModel(model_type = 'bert', \\\n",
    "                                model_name = f'saved_models/model_bert_final', \\\n",
    "                                args = model_args, use_cuda = False)\n",
    "except:\n",
    "    # initialise model\n",
    "    model_args = ClassificationArgs(num_train_epochs=2, learning_rate = 5e-5, \\\n",
    "                                    output_dir = f'saved_models/model_bert_final')\n",
    "    model = ClassificationModel(model_type = 'bert', \\\n",
    "                                 model_name = 'bert-base-uncased', \\\n",
    "                                 num_labels = 3, \\\n",
    "                                 args = model_args, use_cuda = False)\n",
    "    # train the model\n",
    "    model.train_model(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on train (for checking purposes)\n",
    "train_pred, train_raw_outputs = model.predict(df_train.text)\n",
    "\n",
    "# append prediction to df\n",
    "train_pred_df = df.copy()\n",
    "train_pred_df['raw_pred'] = train_pred\n",
    "# convert 2 back to -1\n",
    "train_pred_df['pred'] = train_pred_df.apply(lambda x: -1 if x['raw_pred'] == 2 else x['raw_pred'], axis=1)\n",
    "\n",
    "print(classification_report(train_pred_df.labels, train_pred_df.pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-india",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
